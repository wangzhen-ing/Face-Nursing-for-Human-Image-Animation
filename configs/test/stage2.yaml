output_dir: './exp_output/inference_s2_addfaceno15_V2'
seed: 42
resume_from_checkpoint: 'latest'

stage15_ckpt_step: '56682'
stage15_ckpt_dir: '/cpfs01/projects-HDD/cfff-6f3a36a0cd1e_HDD/zsy_43187/champ/workspaces/wangzhen/code/champ-train-dev/exp_output/champ_stage1_addface_no1.5/saved_models'  # stage1 checkpoint folder
motion_module_path: '/cpfs01/projects-HDD/cfff-6f3a36a0cd1e_HDD/zsy_43187/champ/workspaces/wangzhen/code/champ-train-dev/exp_output/champ_stage2_no1_5/saved_models/motion_module-23165.pth'

num_inference_steps: 20
guidance_scale: 3.5
ref_data_root: ""
data_root: "/cpfs01/projects-HDD/cfff-6f3a36a0cd1e_HDD/public/champ/datasets/archived/Processed_Local_v3"
data_part: "Vanilla_Tiktok_val_w_leg"
guidance_types:
  - 'depth'
  - 'normal'
  - 'semantic_map'
  - 'DWpose'

data:
  guids: 
    - 'depth'
    - 'normal'
    - 'semantic_map'
    - 'DWpose'
  image_size: 768
  face_folder: "/cpfs01/projects-HDD/cfff-6f3a36a0cd1e_HDD/public/champ/temp_with_face_mask"
  face_image_size: 256
  face_guids:
    - "lmk_images"

validation:
  validation_steps: 500
  # aug_type: "Padding"
  aug_type: "Resize"
    

solver:
  gradient_accumulation_steps: 1
  mixed_precision: 'fp16'
  enable_xformers_memory_efficient_attention: False 
  gradient_checkpointing: True 
  max_train_steps: 50000
  max_grad_norm: 1.0
  # lr
  learning_rate: 1e-5
  scale_lr: False 
  lr_warmup_steps: 1
  lr_scheduler: 'constant'

  # optimizer
  use_8bit_adam: True 
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay:  1.0e-2
  adam_epsilon: 1.0e-8

noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start:          0.00085
  beta_end:            0.012
  beta_schedule:       "scaled_linear"
  steps_offset:        1
  clip_sample:         false

guidance_encoder_kwargs:
  guidance_embedding_channels: 320
  guidance_input_channels: 3
  block_out_channels: [16, 32, 96, 256]

unet_additional_kwargs:
  use_latent_attention: true
  num_hie_latent: 1
  use_inflated_groupnorm: true
  unet_use_cross_frame_attention: false 
  unet_use_temporal_attention: false
  use_motion_module: true
  motion_module_resolutions:
  - 1
  - 2
  - 4
  - 8
  motion_module_mid_block: true 
  motion_module_decoder_only: false
  motion_module_type: Vanilla
  motion_module_kwargs:
    num_attention_heads: 8
    num_transformer_block: 1
    attention_block_types:
    - Temporal_Self
    - Temporal_Self
    temporal_position_encoding: true
    temporal_position_encoding_max_len: 32
    temporal_attention_dim_div: 1

base_model_path: 'pretrained_models/stable-diffusion-v1-5'
vae_model_path: 'pretrained_models/sd-vae-ft-mse'
image_encoder_path: 'pretrained_models/image_encoder'
mm_path: './pretrained_models/mm_sd_v15_v2.ckpt'
ipadapter_path: "pretrained_models/ip-adapter-faceid-plusv2_sd15.bin"
image_encoder_ip_path: "pretrained_models/laion_clip"

weight_dtype: 'fp16'  # [fp16, fp32]
uncond_ratio: 0.1
noise_offset: 0.05
snr_gamma: 5.0
enable_zero_snr: True
