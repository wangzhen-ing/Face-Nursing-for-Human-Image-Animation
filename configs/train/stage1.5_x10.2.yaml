exp_name: 'stage1.5_face_x10.9'
output_dir: './exp_output'
seed: 42
resume_from_checkpoint: ''
# fece motion operate by Gaussian filter, face latent operate both in spatial attention and cross attention without mask
stage1_ckpt_step: 56616
stage1_ckpt_dir: '/cpfs01/projects-HDD/cfff-6f3a36a0cd1e_HDD/zsy_43187/champ/workspaces/wangzhen/code/champPlus/exp_output/stage1_face_x10.1/saved_models'  # stage1 checkpoint folder

checkpointing_steps: 1000
save_model_epoch_interval: 20

face_loss_weight: 1

data:
  train_bs: 8
  video_folder: '/cpfs01/projects-HDD/cfff-6f3a36a0cd1e_HDD/zsy_43187/champ/datasets/archived/Processed_Local_v3' # Your data root folder
  guids: 
    # - 'depth'
    # - 'normal'
    # - 'semantic_map'
    - 'DWpose'
  image_size: 1024
  bbox_crop: false
  bbox_resize_ratio: [0.9, 1.5]
  aug_type: "Resize"
  data_parts:
    - "all"
  sample_margin: 30
  select_face: true
  face_folder: "/cpfs01/projects-HDD/cfff-6f3a36a0cd1e_HDD/zsy_43187/champ/workspaces/qingkun/champ_train/temp_with_face_mask"
  face_image_size: 256
  face_guids:
    - "lmk_images"

validation:
  validation_steps: 250
  aug_type: "Padding"
  ref_images:
    - validation_data/ref_images/val-5.png
    - validation_data/ref_images/val-1.png
    - validation_data/ref_images/val-2.png
    # - validation_data/ref_images/val-3.png
    - validation_data/ref_images/val-4.png
    - validation_data/ref_images/037.png
    - validation_data/ref_images/val-6.png
    - validation_data/ref_images/val-7.png
    - validation_data/ref_images/val-9.png
    - validation_data/ref_images/val-10.png


  guidance_folders:
    - validation_data/guid_sequences/000_1
    - validation_data/guid_sequences/000_1
    - validation_data/guid_sequences/000_1
    # - validation_data/guid_sequences/000_1
    - validation_data/guid_sequences/000_1
    - validation_data/guid_sequences/000_1
    - validation_data/guid_sequences/000_1
    - validation_data/guid_sequences/000_1
    - validation_data/guid_sequences/000_1
    - validation_data/guid_sequences/000_1


  region_images:
    - validation_data/region_images/val-5.png
    - validation_data/region_images/val-1.png
    - validation_data/region_images/val-2.png
    # - validation_data/region_images/val-3.png
    - validation_data/region_images/val-4.png
    - validation_data/region_images/037.png
    - validation_data/region_images/val-6.png
    - validation_data/region_images/val-7.png
    - validation_data/region_images/val-9.png
    - validation_data/region_images/val-10.png


    
                    
  guidance_indexes: [30, 30, 60, 90, 120, 30, 30, 30, 30]            

solver:
  gradient_accumulation_steps: 1
  mixed_precision: 'fp16'
  enable_xformers_memory_efficient_attention: True 
  gradient_checkpointing: False 
  max_train_steps: 60000  # 50000
  max_grad_norm: 1.0
  # lr
  learning_rate: 1.0e-5
  scale_lr: False 
  lr_warmup_steps: 1
  lr_scheduler: 'constant'

  # optimizer
  use_8bit_adam: False 
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay:  1.0e-2
  adam_epsilon: 1.0e-8

noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start:          0.00085
  beta_end:            0.012
  beta_schedule:       "scaled_linear"
  steps_offset:        1
  clip_sample:         false

guidance_encoder_kwargs:
  guidance_embedding_channels: 320
  guidance_input_channels: 3
  block_out_channels: [16, 32, 96, 256]

base_model_path: 'pretrained_models/stable-diffusion-v1-5'
vae_model_path: 'pretrained_models/sd-vae-ft-mse'
image_encoder_path: 'pretrained_models/image_encoder'
ipadapter_path: "pretrained_models/ip-adapter-faceid-plusv2_sd15.bin"
image_encoder_ip_path: "pretrained_models/laion_clip"

weight_dtype: 'fp16'  # [fp16, fp32]
uncond_ratio: 0.1
noise_offset: 0.05
snr_gamma: 5.0
enable_zero_snr: True 
 